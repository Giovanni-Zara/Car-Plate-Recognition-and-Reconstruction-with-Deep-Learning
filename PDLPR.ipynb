{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c7490bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12908/776126894.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_frcnn_model _final_version.pth',map_location=\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS AND UTILS\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CTCLoss\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "# DEVICE DEFINITION\n",
    "\n",
    "device=\"cpu\"\n",
    "\n",
    "# BOUNDING BOX FUNCTION \n",
    "\n",
    "def get_bounding_box(file):\n",
    "    numbers=file.split(\"-\")\n",
    "    values=numbers[3]\n",
    "    values_v2=values.split(\"&\")\n",
    "    values_v3=[]\n",
    "    for i in range(len(values_v2)):\n",
    "        if \"_\" in values_v2[i]:\n",
    "            values_v3.append(values_v2[i].split(\"_\"))\n",
    "    t=[values_v2[0],values_v3[0],values_v3[1],values_v3[2],values_v2[-1]]\n",
    "    final_values = [int(x) for item in t for x in (item if isinstance(item, list) else [item])]\n",
    "    x_coords=[final_values[0],final_values[2],final_values[4],final_values[6]]\n",
    "    y_coords=[final_values[1],final_values[3],final_values[5],final_values[7]]\n",
    "    x_min = min(x_coords)\n",
    "    y_min = min(y_coords)\n",
    "    x_max = max(x_coords)\n",
    "    y_max = max(y_coords)\n",
    "    return [float(x_min), float(y_min), float(x_max), float(y_max)]\n",
    "\n",
    "# LOAD FASTER RCNN MODEL\n",
    "\n",
    "def load_Fasterrcnn(device):\n",
    "    model = fasterrcnn_resnet50_fpn(num_classes=2)  \n",
    "    model.load_state_dict(torch.load('best_frcnn_model _final_version.pth',map_location=\"cpu\"))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model=load_Fasterrcnn(\"cpu\")\n",
    "\n",
    "# CAR PLATE TEXT FUNCTION\n",
    "\n",
    "provinces = [\"皖\", \"沪\", \"津\", \"渝\", \"冀\", \"晋\", \"蒙\", \"辽\", \"吉\", \"黑\", \"苏\", \"浙\", \"京\", \"闽\", \"赣\", \"鲁\", \"豫\", \"鄂\", \"湘\", \"粤\", \"桂\", \"琼\", \"川\", \"贵\", \"云\", \"藏\", \"陕\", \"甘\", \"青\", \"宁\", \"新\", \"警\", \"学\", \"O\"]\n",
    "alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'O']\n",
    "ads = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'O']\n",
    "\n",
    "MY_DICTIONARY = provinces + [c for c in alphabet if c not in provinces] + [c for c in ads if c not in provinces and c not in alphabet]    \n",
    "MY_DICTIONARY = list(dict.fromkeys(MY_DICTIONARY))  \n",
    "char2idx = {c: i for i, c in enumerate(MY_DICTIONARY)}\n",
    "idx2char = {i: c for i, c in enumerate(MY_DICTIONARY)}\n",
    "BLANK_IDX = len(MY_DICTIONARY)  \n",
    "\n",
    "def get_text(file):\n",
    "    values=file.split(\"-\")\n",
    "    text=str(values[4])\n",
    "    indices=text.split(\"_\")\n",
    "    province_character=provinces[int(indices[0])]\n",
    "    alphabet_character=alphabet[int(indices[1])]\n",
    "    ads_charachters=[ads[int(i)] for i in indices[2:]]\n",
    "    plate_text=province_character+alphabet_character+\"\".join(ads_charachters)\n",
    "    return plate_text\n",
    "\n",
    "# CROP FUNCTION WITH PREDICTED BOUNDING BOX\n",
    "\n",
    "def crop_image_with_RCNN(file):\n",
    "    image = Image.open(file).convert(\"RGB\")\n",
    "    transform = T.ToTensor()\n",
    "    img_tensor = transform(image).unsqueeze(0).to(device) \n",
    "    with torch.no_grad():\n",
    "        prediction = model(img_tensor)[0]\n",
    "        if len(prediction['boxes']) == 0:\n",
    "            print(f\"No box found for image: {file}\")\n",
    "            return None\n",
    "        best_bb = prediction['boxes'][0].to(device).int()\n",
    "        cropped = img_tensor[0, :, best_bb[1]:best_bb[3], best_bb[0]:best_bb[2]]\n",
    "        cropped_resized = F.interpolate(cropped.unsqueeze(0), size=(48, 144), mode='bilinear', align_corners=False)\n",
    "        return cropped_resized.squeeze(0)  \n",
    "\n",
    "def crop_folder_with_RCNN(folder_path):\n",
    "    cropped_folder = []\n",
    "    files = os.listdir(folder_path)\n",
    "    for file in files:\n",
    "        full_path = os.path.join(folder_path, file)\n",
    "        gt_text=get_text(full_path)\n",
    "        cropped_image = crop_image_with_RCNN(full_path)\n",
    "        if cropped_image is not None:\n",
    "            cropped_folder.append([cropped_image, gt_text])\n",
    "    return cropped_folder\n",
    "\n",
    "def crop_image_with_ground_truth(full_path):\n",
    "    filename = os.path.basename(full_path)  \n",
    "    bb = get_bounding_box(filename)\n",
    "    image = Image.open(full_path).convert(\"RGB\")\n",
    "    transform = T.ToTensor()\n",
    "    img_tensor = transform(image)\n",
    "    cropped = img_tensor[:, int(bb[1]):int(bb[3]), int(bb[0]):int(bb[2])]\n",
    "    cropped_resized = F.interpolate(cropped.unsqueeze(0), size=(48, 144), mode='bilinear', align_corners=False)\n",
    "    return cropped_resized.squeeze(0)\n",
    "\n",
    "def crop_folder_with_ground_truth(folder_path):\n",
    "    cropped_folder = []\n",
    "    files = os.listdir(folder_path)\n",
    "    for file in files:\n",
    "        full_path = os.path.join(folder_path, file)\n",
    "        gt_text = get_text(file)  # Get ground truth text\n",
    "        cropped_image = crop_image_with_ground_truth(full_path)\n",
    "        cropped_folder.append([cropped_image, gt_text])  # Store image and text pair\n",
    "    return cropped_folder\n",
    "\n",
    "def encode_labels(label_list, char2idx, max_len=8):\n",
    "    encoded = []\n",
    "    for label in label_list:\n",
    "        label = label[:max_len].ljust(max_len)\n",
    "        encoded.append([char2idx[c] for c in label])\n",
    "    return torch.tensor(encoded, dtype=torch.long)\n",
    "\n",
    "def ctc_collate_fn(batch):\n",
    "    images, labels = zip(*batch)\n",
    "    images = torch.stack(images)\n",
    "    label_lengths = torch.tensor([len(l) for l in labels], dtype=torch.long)\n",
    "    labels = torch.cat([encode_labels([l], char2idx) for l in labels])\n",
    "    return images, labels, label_lengths\n",
    "\n",
    "def ctc_greedy_decoder(output, idx2char, blank=0):\n",
    "    out = output.permute(1, 0, 2) \n",
    "    pred_strings = []\n",
    "    for probs in out:\n",
    "        pred = probs.argmax(1).cpu().numpy()\n",
    "        prev = -1\n",
    "        pred_str = []\n",
    "        for p in pred:\n",
    "            if p != blank and p != prev:\n",
    "                pred_str.append(idx2char[p])\n",
    "            prev = p\n",
    "        pred_strings.append(''.join(pred_str))\n",
    "    return pred_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7e6e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDLPR MODEL FOLLOWING PAPER ARCHITECTURE\n",
    "\n",
    "# --- Focus Structure Module ---\n",
    "class Focus(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=64, dropout=0.1):\n",
    "        super(Focus, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels * 4, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.act = nn.LeakyReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Slice and concat\n",
    "        patch1 = x[..., ::2, ::2]\n",
    "        patch2 = x[..., ::2, 1::2]\n",
    "        patch3 = x[..., 1::2, ::2]\n",
    "        patch4 = x[..., 1::2, 1::2]\n",
    "        x = torch.cat([patch1, patch2, patch3, patch4], dim=1)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# --- CNN Block used in RESBLOCK and downsampling ---\n",
    "def conv_block(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.LeakyReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Residual Block ---\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            conv_block(channels, channels),\n",
    "            conv_block(channels, channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "\n",
    "# --- IGFE Module ---\n",
    "class IGFE(nn.Module):\n",
    "    def __init__(self, dropout=0.1):\n",
    "        super(IGFE, self).__init__()\n",
    "        self.focus = Focus(3, 64, dropout)\n",
    "        self.down1 = conv_block(64, 128, stride=2)\n",
    "        self.res1 = ResBlock(128)\n",
    "        self.res2 = ResBlock(128)\n",
    "        self.down2 = conv_block(128, 256, stride=2)\n",
    "        self.res3 = ResBlock(256)\n",
    "        self.res4 = ResBlock(256)\n",
    "        self.final_conv = nn.Conv2d(256, 512, kernel_size=1)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((6, 18))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.focus(x)\n",
    "        x = self.down1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.res1(x)\n",
    "        x = self.res2(x)\n",
    "        x = self.down2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.res3(x)\n",
    "        x = self.res4(x)\n",
    "        x = self.final_conv(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# --- Positional Encoding for 2D feature maps ---\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, height, width):\n",
    "        super().__init__()\n",
    "        self.pe = nn.Parameter(torch.randn(1, d_model, height, width))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe\n",
    "\n",
    "\n",
    "# --- Transformer Encoder Block ---\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(d_model, d_model * 2, kernel_size=1)\n",
    "        self.attn = nn.MultiheadAttention(d_model * 2, num_heads=8, batch_first=True)\n",
    "        self.cnn2 = nn.Conv2d(d_model * 2, d_model, kernel_size=1)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x = self.cnn1(x)  # [B, 1024, H, W]\n",
    "        x_ = x.flatten(2).transpose(1, 2)  # [B, HW, 1024]\n",
    "        x_, _ = self.attn(x_, x_, x_)\n",
    "        x_ = x_.transpose(1, 2).view(B, -1, H, W)  # [B, 1024, H, W]\n",
    "        x = self.cnn2(x_)\n",
    "        return self.norm(x.flatten(2).transpose(1, 2)).transpose(1, 2).view(B, C, H, W)\n",
    "\n",
    "# --- Parallel Decoder Block ---\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, num_heads=8, batch_first=True)\n",
    "        self.cross_attn = nn.MultiheadAttention(d_model, num_heads=8, batch_first=True)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model * 2, d_model)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, tgt, memory):\n",
    "        # Masked self-attention (causal)\n",
    "        B, T, _ = tgt.shape\n",
    "        mask = torch.triu(torch.ones(T, T), diagonal=1).bool().to(tgt.device)\n",
    "        tgt2, _ = self.self_attn(tgt, tgt, tgt, attn_mask=mask)\n",
    "        tgt = self.norm1(tgt + tgt2)\n",
    "\n",
    "        # Cross-attention\n",
    "        tgt2, _ = self.cross_attn(tgt, memory, memory)\n",
    "        tgt = self.norm2(tgt + tgt2)\n",
    "\n",
    "        # Feedforward\n",
    "        tgt2 = self.ffn(tgt)\n",
    "        tgt = self.norm3(tgt + tgt2)\n",
    "        return tgt\n",
    "\n",
    "\n",
    "# --- Full PDLPR Recognition Model ---\n",
    "class PDLPR(nn.Module):\n",
    "    def __init__(self, num_classes, dropout=0.1):\n",
    "        super(PDLPR, self).__init__()\n",
    "        self.igfe = IGFE(dropout)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((6, 18))\n",
    "        self.pos_encoding = PositionalEncoding(512, 6, 18)\n",
    "        self.encoder = nn.Sequential(*[EncoderBlock(512) for _ in range(3)])\n",
    "        self.flatten = lambda x: x.flatten(2).transpose(1, 2)\n",
    "        self.decoder_blocks = nn.ModuleList([DecoderBlock(512) for _ in range(3)])\n",
    "        self.cls_head = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, tgt_seq):\n",
    "        # Clean up any GPU memory\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        x = self.igfe(x)                     \n",
    "        x = self.adaptive_pool(x)            \n",
    "        x = self.dropout(x)\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.encoder(x)\n",
    "        memory = self.flatten(x)             \n",
    "\n",
    "        tgt = tgt_seq                        \n",
    "        for block in self.decoder_blocks:\n",
    "            tgt = block(tgt, memory)\n",
    "            tgt = self.dropout(tgt)\n",
    "\n",
    "        logits = self.cls_head(tgt)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec71f832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12908/776126894.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_frcnn_model _final_version.pth',map_location=\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "# CHOICE OF THE DATASET\n",
    "\n",
    "class CroppedImages(Dataset):\n",
    "    def __init__(self, folder, transformations):\n",
    "        self.folder = folder\n",
    "        self.transformations = transformations\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.folder)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            image = self.folder[idx][0]\n",
    "            gt_text = self.folder[idx][1]\n",
    "            \n",
    "            if image is None:\n",
    "                raise ValueError(f\"None image at index {idx}\")\n",
    "                \n",
    "            if self.transformations:\n",
    "                image = self.transformations(image)\n",
    "                \n",
    "            return image, gt_text\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading sample {idx}: {str(e)}\")\n",
    "            return torch.zeros(3, 48, 144), \"\"\n",
    "\n",
    "model=load_Fasterrcnn(device=\"cpu\")\n",
    "device=\"cpu\"\n",
    "model.eval()\n",
    "\n",
    "# Updated transformations with better normalization and data augmentation\n",
    "trans = T.Compose([\n",
    "    T.Resize((48, 144), antialias=True),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2),  # Add some color variation\n",
    "    T.RandomApply([T.GaussianBlur(3, sigma=(0.1, 0.2))], p=0.3),  # Occasional blur\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet normalization\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "cropped_folder_train=crop_folder_with_RCNN(\"/home/filippo/Documents/Visual Studio Code/Computer_Vision/Prove/single_sample_train\")\n",
    "cropped_folder_eval=crop_folder_with_RCNN(\"/home/filippo/Documents/Visual Studio Code/Computer_Vision/Prove/single_sample_eval\")\n",
    "\n",
    "train_dataset = CroppedImages(cropped_folder_train, trans)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=False, collate_fn=ctc_collate_fn)\n",
    "\n",
    "eval_dataset = CroppedImages(cropped_folder_eval, trans)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=8, shuffle=False, collate_fn=ctc_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90dfa9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.7622341..1.2607107].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded ground truth: [0, 35, 37, 58, 61, 67, 64, 58]\n",
      "Decoded ground truth: 皖BD03960\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_item=next(iter(train_dataloader)) \n",
    "# returns a dataloader in which each item is a tuple (element in position 0: cropped image with shape [3, 48, 144], element in position 1: a 1X8 tensor of encoded car text,\n",
    "# element in position 2: a tensor with (8))\n",
    "image = train_item[0].squeeze()\n",
    "encoded_text = train_item[1]\n",
    "text_length = train_item[2]\n",
    "\n",
    "# Decode the ground truth text\n",
    "decoded_text = ''.join([idx2char[idx.item()] for idx in encoded_text[0][:text_length[0]]])\n",
    "\n",
    "print(f\"Encoded ground truth: {encoded_text[0].tolist()}\")\n",
    "print(f\"Decoded ground truth: {decoded_text}\")\n",
    "\n",
    "# showing the image (if the image sucks put trans=None in the above cell and run again)\n",
    "plt.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Cropped Image - Ground Truth: {decoded_text}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1cf61ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/filippo/miniconda3/envs/virtualenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/filippo/miniconda3/envs/virtualenv/lib/python3.12/site-packages/torch/autograd/graph.py:825: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647329220/work/c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Loss = 4.1541\n",
      "Saved new best model with validation loss: 4.6602\n",
      "\n",
      "Epoch 1/15\n",
      "Train Loss: 4.1541 | True Train Accuracy: 0.0000\n",
      "Val Loss: 4.6602 | True Val Accuracy: 0.0000\n",
      "Current Learning Rate: 0.000500\n",
      "--------------------------------------------------\n",
      "Batch 0: Loss = 2.7617\n",
      "Saved new best model with validation loss: 4.0939\n",
      "\n",
      "Epoch 2/15\n",
      "Train Loss: 2.7617 | True Train Accuracy: 0.0000\n",
      "Val Loss: 4.0939 | True Val Accuracy: 0.0000\n",
      "Current Learning Rate: 0.000500\n",
      "--------------------------------------------------\n",
      "Batch 0: Loss = 3.0619\n",
      "\n",
      "Epoch 3/15\n",
      "Train Loss: 3.0619 | True Train Accuracy: 0.0000\n",
      "Val Loss: 4.4631 | True Val Accuracy: 0.0000\n",
      "Current Learning Rate: 0.000500\n",
      "--------------------------------------------------\n",
      "Batch 0: Loss = 2.1961\n",
      "\n",
      "Epoch 4/15\n",
      "Train Loss: 2.1961 | True Train Accuracy: 0.0000\n",
      "Val Loss: 4.8479 | True Val Accuracy: 0.0000\n",
      "Current Learning Rate: 0.000500\n",
      "--------------------------------------------------\n",
      "Batch 0: Loss = 2.3496\n",
      "\n",
      "Epoch 5/15\n",
      "Train Loss: 2.3496 | True Train Accuracy: 0.0000\n",
      "Val Loss: 4.4394 | True Val Accuracy: 0.0000\n",
      "Current Learning Rate: 0.000500\n",
      "--------------------------------------------------\n",
      "Batch 0: Loss = 2.2563\n",
      "\n",
      "Epoch 6/15\n",
      "Train Loss: 2.2563 | True Train Accuracy: 0.0000\n",
      "Val Loss: 4.3745 | True Val Accuracy: 0.0000\n",
      "Current Learning Rate: 0.000350\n",
      "--------------------------------------------------\n",
      "Batch 0: Loss = 2.1070\n",
      "\n",
      "Epoch 7/15\n",
      "Train Loss: 2.1070 | True Train Accuracy: 0.0000\n",
      "Val Loss: 4.5912 | True Val Accuracy: 0.0000\n",
      "Current Learning Rate: 0.000350\n",
      "--------------------------------------------------\n",
      "Early stopping triggered after 7 epochs\n"
     ]
    }
   ],
   "source": [
    "# COMPLETE PDLPR TRAINING AND EVALUATION WITH CTC LOSS\n",
    "\n",
    "# Device setup \n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Model setup\n",
    "model = PDLPR(num_classes=len(MY_DICTIONARY)+1, dropout=0.1).to(device)\n",
    "criterion = CTCLoss(blank=BLANK_IDX, zero_infinity=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.0005)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min', \n",
    "    factor=0.7,\n",
    "    patience=3,\n",
    "    verbose=True,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 15\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    true_train_accuracy = 0\n",
    "\n",
    "    for batch_idx, (batch_images, batch_labels, label_lengths) in enumerate(train_dataloader):\n",
    "        try:\n",
    "            batch_images = batch_images.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            label_lengths = label_lengths.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            B = batch_images.size(0)\n",
    "            tgt_seq = torch.zeros(B, 8, 512).to(device)\n",
    "            \n",
    "            # Forward pass \n",
    "            logits = model(batch_images, tgt_seq)\n",
    "            log_probs = logits.log_softmax(2)\n",
    "            \n",
    "            input_lengths = torch.full(size=(B,), \n",
    "                                    fill_value=8,\n",
    "                                    dtype=torch.long,\n",
    "                                    device=device)\n",
    "            \n",
    "            # Calculate CTC loss\n",
    "            loss = criterion(log_probs.permute(1, 0, 2),\n",
    "                           batch_labels,\n",
    "                           input_lengths,\n",
    "                           label_lengths)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy using CTC decoder\n",
    "            pred_text = ctc_greedy_decoder(log_probs.permute(1, 0, 2), idx2char)\n",
    "            for i in range(B):\n",
    "                true_text = ''.join([idx2char[idx.item()] for idx in batch_labels[i][:label_lengths[i]]])\n",
    "                if pred_text[i] == true_text:\n",
    "                    true_train_accuracy += 1\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Batch {batch_idx}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in batch {batch_idx}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_dataloader)\n",
    "    true_train_acc = true_train_accuracy / (len(train_dataloader) * B)\n",
    "\n",
    "    # Evaluation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    true_val_accuracy = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_images, batch_labels, label_lengths in eval_dataloader:\n",
    "            batch_images = batch_images.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            label_lengths = label_lengths.to(device)\n",
    "\n",
    "            B = batch_images.size(0)\n",
    "            tgt_seq = torch.zeros(B, 8, 512).to(device)\n",
    "\n",
    "            logits = model(batch_images, tgt_seq)\n",
    "            log_probs = logits.log_softmax(2)\n",
    "\n",
    "            input_lengths = torch.full(size=(B,), \n",
    "                                    fill_value=8,\n",
    "                                    dtype=torch.long,\n",
    "                                    device=device)\n",
    "\n",
    "            loss = criterion(log_probs.permute(1, 0, 2),\n",
    "                           batch_labels,\n",
    "                           input_lengths,\n",
    "                           label_lengths)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy using CTC decoder\n",
    "            pred_text = ctc_greedy_decoder(log_probs.permute(1, 0, 2), idx2char)\n",
    "            for i in range(B):\n",
    "                true_text = ''.join([idx2char[idx.item()] for idx in batch_labels[i][:label_lengths[i]]])\n",
    "                if pred_text[i] == true_text:\n",
    "                    true_val_accuracy += 1\n",
    "\n",
    "    avg_val_loss = val_loss / len(eval_dataloader)\n",
    "    true_val_acc = true_val_accuracy / (len(eval_dataloader) * B)\n",
    "\n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Save best model\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'best_val_loss': best_val_loss\n",
    "        }, 'best_pdlpr_model_ctc.pth')\n",
    "        print(f\"Saved new best model with validation loss: {best_val_loss:.4f}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    # Print epoch statistics\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f} | True Train Accuracy: {true_train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {avg_val_loss:.4f} | True Val Accuracy: {true_val_acc:.4f}\")\n",
    "    print(f\"Current Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Early stopping\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70925e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9813/160895573.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('best_pdlpr_model_ctc.pth', map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted license plate: ['0', '0', '0', '0', '0', '0', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('best_pdlpr_model_ctc.pth', map_location=device)\n",
    "model = PDLPR(num_classes=len(MY_DICTIONARY) + 1, dropout=0.1)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "cropped_image=crop_image_with_ground_truth(\"/home/filippo/Documents/Visual Studio Code/Computer_Vision/Prove/single_sample_eval//03625-92_266-225&396_573&501-568&501_227&490_225&396_573&414-0_0_3_17_25_28_27_30-102-83.jpg\")\n",
    "transformed = trans(cropped_image).unsqueeze(0).to(device)  \n",
    "\n",
    "tgt_seq = torch.zeros(1, 8, 512).to(device)  # batch size = 1, seq len = 8\n",
    "\n",
    "# ---- Inference ----\n",
    "with torch.no_grad():\n",
    "    logits = model(transformed, tgt_seq)         # [B, T, num_classes]\n",
    "    log_probs = logits.log_softmax(2)\n",
    "pred_text = ctc_greedy_decoder(log_probs, idx2char, blank=0)\n",
    "print(f\"Predicted license plate: {pred_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
